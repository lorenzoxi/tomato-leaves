{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class PWConv_Batch_Relu(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "    ):\n",
    "        super(PWConv_Batch_Relu, self).__init__()\n",
    "        self.pw_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PWConv_Batch(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "    ):\n",
    "        super(PWConv_Batch, self).__init__()\n",
    "        self.pw_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pw_conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DwConv_Batch(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "    ):\n",
    "        super(DwConv_Batch, self).__init__()\n",
    "        self.dw_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=in_channels,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DwConv_Batch_Relu(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "    ):\n",
    "        super(DwConv_Batch_Relu, self).__init__()\n",
    "        self.dw_conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=in_channels,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ECA(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size=3, bias=False):\n",
    "        super(ECA, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, bias=bias\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = y.squeeze(-1).transpose(-1, -2)\n",
    "        y = self.conv(y)\n",
    "        y = self.sigmoid(y)\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "class SGECA(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, first_out_channel, final_stride=2, config=2\n",
    "    ):\n",
    "        super(SGECA, self).__init__()\n",
    "        self.config = config\n",
    "        self.use_shortcut = config and (\n",
    "            in_channels == out_channels and final_stride == 1\n",
    "        )\n",
    "\n",
    "        if config == 1:\n",
    "            self.pw_conv1 = PWConv_Batch_Relu(\n",
    "                in_channels,\n",
    "                first_out_channel,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.eca = ECA(in_channels=first_out_channel, kernel_size=3, bias=False)\n",
    "            self.pw_conv2 = PWConv_Batch(\n",
    "                first_out_channel,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.dw_conv = DwConv_Batch(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=final_stride,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            )\n",
    "        else:\n",
    "            self.dw_conv = DwConv_Batch_Relu(\n",
    "                in_channels, in_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "            )\n",
    "            self.pw_conv1 = PWConv_Batch_Relu(\n",
    "                in_channels,\n",
    "                first_out_channel,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.eca = ECA(in_channels=first_out_channel, kernel_size=3, bias=False)\n",
    "            self.pw_conv2 = PWConv_Batch(\n",
    "                first_out_channel,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.dw_conv2 = DwConv_Batch(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=final_stride,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.activate_shortcut = (in_channels == out_channels) and (final_stride == 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.config == 1:\n",
    "            x = self.pw_conv1(x)\n",
    "            x = self.eca(x)\n",
    "            x = self.pw_conv2(x)\n",
    "            x = self.dw_conv(x)\n",
    "        elif self.config == 2:\n",
    "            \n",
    "            original_x = x\n",
    "            \n",
    "            x = self.dw_conv(x)\n",
    "            x = self.pw_conv1(x)\n",
    "            x = self.eca(x)\n",
    "            x = self.pw_conv2(x)\n",
    "            x = self.dw_conv2(x)\n",
    "            if self.activate_shortcut:\n",
    "                x = x + original_x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ParC_operator(nn.Module):\n",
    "    def __init__(self, dim, type, global_kernel_size, use_pe=True):\n",
    "        super().__init__()\n",
    "        self.type = type  # H or W\n",
    "        self.dim = dim\n",
    "        self.use_pe = use_pe\n",
    "        self.global_kernel_size = global_kernel_size\n",
    "        self.kernel_size = (\n",
    "            (global_kernel_size, 1) if self.type == \"H\" else (1, global_kernel_size)\n",
    "        )\n",
    "        self.gcc_conv = nn.Conv2d(dim, dim, kernel_size=self.kernel_size, groups=dim)\n",
    "        if use_pe:\n",
    "            if self.type == \"H\":\n",
    "                self.pe = nn.Parameter(torch.randn(1, dim, self.global_kernel_size, 1))\n",
    "            elif self.type == \"W\":\n",
    "                self.pe = nn.Parameter(torch.randn(1, dim, 1, self.global_kernel_size))\n",
    "            init.trunc_normal_(self.pe, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_pe:\n",
    "            x = x + self.pe.expand(\n",
    "                1, self.dim, self.global_kernel_size, self.global_kernel_size\n",
    "            )\n",
    "\n",
    "        x_cat = (\n",
    "            torch.cat((x, x[:, :, :-1, :]), dim=2)\n",
    "            if self.type == \"H\"\n",
    "            else torch.cat((x, x[:, :, :, :-1]), dim=3)\n",
    "        )\n",
    "        x = self.gcc_conv(x_cat)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ParcSG(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        dim,\n",
    "        global_kernel_size=14,\n",
    "        use_pe=True,\n",
    "        first_out_channel=4,\n",
    "    ):\n",
    "        super(ParcSG, self).__init__()\n",
    "        self.parc_H = ParC_operator(dim // 2, \"H\", global_kernel_size, use_pe=use_pe)\n",
    "        self.parc_W = ParC_operator(dim // 2, \"W\", global_kernel_size, use_pe=use_pe)\n",
    "        self.pw_1 = PWConv_Batch_Relu(\n",
    "            in_channels,\n",
    "            first_out_channel,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.pw2 = PWConv_Batch(\n",
    "            first_out_channel,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.dw = DwConv_Batch_Relu(\n",
    "            out_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_H, x_W = torch.chunk(x, 2, dim=1)\n",
    "        x_H = self.parc_H(x_H)\n",
    "        x_W = self.parc_W(x_W)\n",
    "\n",
    "        # print(f\"x_H: {x_H.shape}\")\n",
    "        # print(f\"x_W: {x_W.shape}\")\n",
    "\n",
    "        target_size = (max(x_H.shape[2], x_W.shape[2]), max(x_H.shape[3], x_W.shape[3]))\n",
    "        x_H_resized = F.interpolate(\n",
    "            x_H, size=target_size, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        x_V_resized = F.interpolate(\n",
    "            x_W, size=target_size, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "\n",
    "        x = torch.cat((x_H_resized, x_V_resized), dim=1)\n",
    "        # print(f\"Final x: {x.shape}\")\n",
    "\n",
    "        x = self.pw_1(x)\n",
    "        x = self.pw2(x)\n",
    "        x = self.dw(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the model to test output shape\n",
    "class LSGNet(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(LSGNet, self).__init__()\n",
    "\n",
    "        input_tensor = torch.randn(1, 3, 224, 224)\n",
    "        # Layer 1 (Conv 3x3, BN, ReLU)\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        output_tensor = self.conv1(input_tensor)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        output_tensor = self.bn1(output_tensor)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        output_tensor = self.relu(output_tensor)\n",
    "        # print(f\"    Layer #1: Shape of output tensor: {output_tensor.shape}\")\n",
    "\n",
    "        # Layer 2\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        output_tensor = self.maxpool(output_tensor)\n",
    "        # print(f\"    Layer #2: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #2: Number of parameters: {count_parameters(self.maxpool)}\")\n",
    "\n",
    "        # Layer 3: SGECA (pw_eca_pw_dw)\n",
    "        self.sgeca1 = SGECA(24, 116, first_out_channel=32, config=1)\n",
    "        output_tensor = self.sgeca1(output_tensor)\n",
    "        # print(f\"    Layer #3: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #3: Number of parameters: {count_parameters(self.sgeca1)}\")\n",
    "\n",
    "        # Layer 4: SGECA (dw_pw_eca_pw)\n",
    "        self.sgeca2 = SGECA(116, 116, first_out_channel=32, final_stride=1, config=2)\n",
    "        output_tensor = self.sgeca2(output_tensor)\n",
    "        # print(f\"    Layer #4: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #4: Number of parameters: {count_parameters(self.sgeca2)}\")\n",
    "\n",
    "        # Layer 5: SGECA (pw_eca_pw_dw)\n",
    "        self.sgeca3 = SGECA(116, 232, first_out_channel=48, config=1)\n",
    "        output_tensor = self.sgeca3(output_tensor)\n",
    "        # print(f\"    Layer #5: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #5: Number of parameters: {count_parameters(self.sgeca3)}\")\n",
    "\n",
    "        # Layer 6: SGECA (dw_pw_eca_pw)\n",
    "        self.sgeca4 = SGECA(232, 232, first_out_channel=48, final_stride=1, config=2)\n",
    "        output_tensor = self.sgeca4(output_tensor)\n",
    "        # print(f\"    Layer #6: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #6: Number of parameters: {count_parameters(self.sgeca4)}\")\n",
    "\n",
    "        # Layer 7: ParcSG\n",
    "        self.parcsg1 = ParcSG(\n",
    "            in_channels=232,\n",
    "            out_channels=232,\n",
    "            dim=232,\n",
    "            global_kernel_size=1,\n",
    "            use_pe=True,\n",
    "            first_out_channel=56,\n",
    "        )\n",
    "        output_tensor = self.parcsg1(output_tensor)\n",
    "        # print(f\"    Layer #7: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #7: Number of parameters: {count_parameters(self.parcsg1)}\")\n",
    "\n",
    "        # Layer 8: ParcSG\n",
    "        self.parcsg2 = ParcSG(\n",
    "            in_channels=232,\n",
    "            out_channels=232,\n",
    "            dim=232,\n",
    "            global_kernel_size=1,\n",
    "            use_pe=True,\n",
    "            first_out_channel=56,\n",
    "        )\n",
    "        output_tensor = self.parcsg2(output_tensor)\n",
    "        # print(f\"    Layer #8: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #8: Number of parameters: {count_parameters(self.parcsg2)}\")\n",
    "\n",
    "        # Layer 9: SGECA (pw_eca_pw_dw)\n",
    "        self.sgeca5 = SGECA(232, 464, first_out_channel=80, config=1)\n",
    "        output_tensor = self.sgeca5(output_tensor)\n",
    "        # print(f\"    Layer #9: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #9: Number of parameters: {count_parameters(self.sgeca5)}\")\n",
    "\n",
    "        # Layer 10: ParcSG\n",
    "        self.parcsg3 = ParcSG(\n",
    "            in_channels=464,\n",
    "            out_channels=464,\n",
    "            dim=464,\n",
    "            global_kernel_size=1,\n",
    "            use_pe=True,\n",
    "            first_out_channel=84,\n",
    "        )\n",
    "        output_tensor = self.parcsg3(output_tensor)\n",
    "        # print(f\"    Layer #10: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #10: Number of parameters: {count_parameters(self.parcsg3)}\")\n",
    "\n",
    "        # Layer 11: (Conv 1x1 (stride=1), BN, ReLU)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            464, 1024, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(1024)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        output_tensor = self.relu2(self.bn2(self.conv2(output_tensor)))\n",
    "        # print(f\"    Layer #11: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(f\"Layer #11: Number of parameters: {count_parameters(self.conv2)}\")\n",
    "\n",
    "        # Layer 12: Global Average Pooling\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # print(f\"    Layer #12: Shape of output tensor: {output_tensor.shape}\")\n",
    "        # print(\n",
    "        #     f\"Layer #12: Number of parameters: {count_parameters(self.global_avgpool)}\"\n",
    "        # )\n",
    "\n",
    "        # Layer 13: Classifier\n",
    "        self.fc = nn.Linear(1024, num_classes, bias=True)\n",
    "        # print(f\"Layer #13: Number of parameters: {count_parameters(self.fc)}\")\n",
    "        # print(f\"Total number of parameters: {count_parameters(self)}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.sgeca1(x)\n",
    "        x = self.sgeca2(x)\n",
    "        x = self.sgeca3(x)\n",
    "        x = self.sgeca4(x)\n",
    "        x = self.parcsg1(x)\n",
    "        x = self.parcsg2(x)\n",
    "        x = self.sgeca5(x)\n",
    "        x = self.parcsg3(x)\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.global_avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def save_model(model, filename=\"model_state_dict.pth\"):\n",
    "  torch.save(model, f\"{filename}.pth\")\n",
    "  torch.save(model.state_dict(), f\"s_{filename}.pth\")\n",
    "\n",
    "def validate(device, model, val_loader):\n",
    "    model.eval()\n",
    "    num_classes = len(val_loader.dataset.classes) \n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        class_correct = {}\n",
    "        class_total = {}\n",
    "        false_positives = {}\n",
    "        false_negatives = {}\n",
    "        start = time.time()\n",
    "        \n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for label, prediction in zip(labels, predicted):\n",
    "                confusion_matrix[label.item(), prediction.item()] += 1  # Update the confusion matrix\n",
    "                if label == prediction:\n",
    "                    class_correct[label.item()] = class_correct.get(label.item(), 0) + 1\n",
    "                else:\n",
    "                    false_negatives[label.item()] = false_negatives.get(label.item(), 0) + 1\n",
    "                    false_positives[prediction.item()] = false_positives.get(prediction.item(), 0) + 1\n",
    "\n",
    "                class_total[label.item()] = class_total.get(label.item(), 0) + 1\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "\n",
    "        for class_id in class_total.keys():\n",
    "            tp = class_correct.get(class_id, 0)\n",
    "            fp = false_positives.get(class_id, 0)\n",
    "            fn = false_negatives.get(class_id, 0)\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "\n",
    "        # Calculate overall precision, recall\n",
    "        end = time.time()\n",
    "        computation_time = end - start\n",
    "        \n",
    "        overall_precision = sum(precision_list) / len(precision_list) if len(precision_list) > 0 else 0\n",
    "        overall_recall = sum(recall_list) / len(recall_list) if len(recall_list) > 0 else 0\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "        print(f'Accuracy: {accuracy:.2f}%')\n",
    "        print(f'Precision: {overall_precision:.2f}')\n",
    "        print(f'Recall: {overall_recall:.2f}')\n",
    "\n",
    "        return accuracy, overall_precision, overall_recall, confusion_matrix\n",
    "    \n",
    "\n",
    "def train(device, model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.to(device).float()\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Start epoch {epoch+1}/{num_epochs}')\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.2f}')\n",
    "\n",
    "    end = time.time()\n",
    "    computation_time = end - start \n",
    "    print(f'Training completed in {(end - start):.2f} seconds')\n",
    "    print(f'Training accuracy: {train_accuracy:.2f}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    return train_accuracy, train_losses, computation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 757203\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.ColorJitter(saturation=0.5),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transforms_validation_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "num_epochs = 150\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "dataset_path_training = '../../dataset-tomatoes/train'\n",
    "dataset_path_validation = '../../dataset-tomatoes/validation'\n",
    "validation_dataset = ImageFolder(root=dataset_path_validation, transform=data_transforms_validation_test)\n",
    "train_dataset = ImageFolder(root=dataset_path_training, transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': validation_loader\n",
    "}\n",
    "\n",
    "# Initialize the model, criterion, optimizer\n",
    "model = LSGNet(num_classes=8)\n",
    "print(f\"Number of trainable parameters: {count_parameters(model)}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 1/150\n",
      "Epoch 1/150, Loss: 1.4614, Accuracy: 0.48\n",
      "Start epoch 2/150\n",
      "Epoch 2/150, Loss: 1.0703, Accuracy: 0.63\n",
      "Start epoch 3/150\n",
      "Epoch 3/150, Loss: 0.9040, Accuracy: 0.70\n",
      "Start epoch 4/150\n",
      "Epoch 4/150, Loss: 0.7961, Accuracy: 0.73\n",
      "Start epoch 5/150\n",
      "Epoch 5/150, Loss: 0.7185, Accuracy: 0.75\n",
      "Start epoch 6/150\n",
      "Epoch 6/150, Loss: 0.6595, Accuracy: 0.78\n",
      "Start epoch 7/150\n",
      "Epoch 7/150, Loss: 0.6123, Accuracy: 0.79\n",
      "Start epoch 8/150\n",
      "Epoch 8/150, Loss: 0.5718, Accuracy: 0.80\n",
      "Start epoch 9/150\n",
      "Epoch 9/150, Loss: 0.5280, Accuracy: 0.82\n",
      "Start epoch 10/150\n",
      "Epoch 10/150, Loss: 0.4936, Accuracy: 0.83\n",
      "Start epoch 11/150\n",
      "Epoch 11/150, Loss: 0.4694, Accuracy: 0.84\n",
      "Start epoch 12/150\n",
      "Epoch 12/150, Loss: 0.4535, Accuracy: 0.85\n",
      "Start epoch 13/150\n",
      "Epoch 13/150, Loss: 0.4197, Accuracy: 0.86\n",
      "Start epoch 14/150\n",
      "Epoch 14/150, Loss: 0.3997, Accuracy: 0.86\n",
      "Start epoch 15/150\n",
      "Epoch 15/150, Loss: 0.3855, Accuracy: 0.87\n",
      "Start epoch 16/150\n",
      "Epoch 16/150, Loss: 0.3872, Accuracy: 0.87\n",
      "Start epoch 17/150\n",
      "Epoch 17/150, Loss: 0.3611, Accuracy: 0.88\n",
      "Start epoch 18/150\n",
      "Epoch 18/150, Loss: 0.3497, Accuracy: 0.88\n",
      "Start epoch 19/150\n",
      "Epoch 19/150, Loss: 0.3419, Accuracy: 0.88\n",
      "Start epoch 20/150\n",
      "Epoch 20/150, Loss: 0.3139, Accuracy: 0.89\n",
      "Start epoch 21/150\n",
      "Epoch 21/150, Loss: 0.3171, Accuracy: 0.89\n",
      "Start epoch 22/150\n",
      "Epoch 22/150, Loss: 0.3001, Accuracy: 0.90\n",
      "Start epoch 23/150\n",
      "Epoch 23/150, Loss: 0.3024, Accuracy: 0.90\n",
      "Start epoch 24/150\n",
      "Epoch 24/150, Loss: 0.2939, Accuracy: 0.90\n",
      "Start epoch 25/150\n",
      "Epoch 25/150, Loss: 0.2824, Accuracy: 0.90\n",
      "Start epoch 26/150\n",
      "Epoch 26/150, Loss: 0.2851, Accuracy: 0.90\n",
      "Start epoch 27/150\n",
      "Epoch 27/150, Loss: 0.2835, Accuracy: 0.90\n",
      "Start epoch 28/150\n",
      "Epoch 28/150, Loss: 0.2671, Accuracy: 0.91\n",
      "Start epoch 29/150\n",
      "Epoch 29/150, Loss: 0.2551, Accuracy: 0.91\n",
      "Start epoch 30/150\n",
      "Epoch 30/150, Loss: 0.2480, Accuracy: 0.91\n",
      "Start epoch 31/150\n",
      "Epoch 31/150, Loss: 0.2565, Accuracy: 0.91\n",
      "Start epoch 32/150\n",
      "Epoch 32/150, Loss: 0.2468, Accuracy: 0.91\n",
      "Start epoch 33/150\n",
      "Epoch 33/150, Loss: 0.2481, Accuracy: 0.91\n",
      "Start epoch 34/150\n",
      "Epoch 34/150, Loss: 0.2334, Accuracy: 0.92\n",
      "Start epoch 35/150\n",
      "Epoch 35/150, Loss: 0.2412, Accuracy: 0.92\n",
      "Start epoch 36/150\n",
      "Epoch 36/150, Loss: 0.2369, Accuracy: 0.92\n",
      "Start epoch 37/150\n",
      "Epoch 37/150, Loss: 0.2269, Accuracy: 0.92\n",
      "Start epoch 38/150\n",
      "Epoch 38/150, Loss: 0.2182, Accuracy: 0.92\n",
      "Start epoch 39/150\n",
      "Epoch 39/150, Loss: 0.2092, Accuracy: 0.93\n",
      "Start epoch 40/150\n",
      "Epoch 40/150, Loss: 0.2028, Accuracy: 0.93\n",
      "Start epoch 41/150\n",
      "Epoch 41/150, Loss: 0.2179, Accuracy: 0.93\n",
      "Start epoch 42/150\n",
      "Epoch 42/150, Loss: 0.2216, Accuracy: 0.93\n",
      "Start epoch 43/150\n",
      "Epoch 43/150, Loss: 0.2068, Accuracy: 0.93\n",
      "Start epoch 44/150\n",
      "Epoch 44/150, Loss: 0.1896, Accuracy: 0.93\n",
      "Start epoch 45/150\n",
      "Epoch 45/150, Loss: 0.1856, Accuracy: 0.93\n",
      "Start epoch 46/150\n",
      "Epoch 46/150, Loss: 0.2049, Accuracy: 0.93\n",
      "Start epoch 47/150\n",
      "Epoch 47/150, Loss: 0.1989, Accuracy: 0.93\n",
      "Start epoch 48/150\n",
      "Epoch 48/150, Loss: 0.1695, Accuracy: 0.94\n",
      "Start epoch 49/150\n",
      "Epoch 49/150, Loss: 0.1790, Accuracy: 0.94\n",
      "Start epoch 50/150\n",
      "Epoch 50/150, Loss: 0.1754, Accuracy: 0.94\n",
      "Start epoch 51/150\n",
      "Epoch 51/150, Loss: 0.1957, Accuracy: 0.94\n",
      "Start epoch 52/150\n",
      "Epoch 52/150, Loss: 0.1907, Accuracy: 0.94\n",
      "Start epoch 53/150\n",
      "Epoch 53/150, Loss: 0.1649, Accuracy: 0.94\n",
      "Start epoch 54/150\n",
      "Epoch 54/150, Loss: 0.1722, Accuracy: 0.94\n",
      "Start epoch 55/150\n",
      "Epoch 55/150, Loss: 0.1866, Accuracy: 0.94\n",
      "Start epoch 56/150\n",
      "Epoch 56/150, Loss: 0.1728, Accuracy: 0.94\n",
      "Start epoch 57/150\n",
      "Epoch 57/150, Loss: 0.1726, Accuracy: 0.94\n",
      "Start epoch 58/150\n",
      "Epoch 58/150, Loss: 0.1846, Accuracy: 0.94\n",
      "Start epoch 59/150\n",
      "Epoch 59/150, Loss: 0.1691, Accuracy: 0.94\n",
      "Start epoch 60/150\n",
      "Epoch 60/150, Loss: 0.1718, Accuracy: 0.94\n",
      "Start epoch 61/150\n",
      "Epoch 61/150, Loss: 0.1506, Accuracy: 0.95\n",
      "Start epoch 62/150\n",
      "Epoch 62/150, Loss: 0.1495, Accuracy: 0.95\n",
      "Start epoch 63/150\n",
      "Epoch 63/150, Loss: 0.1391, Accuracy: 0.95\n",
      "Start epoch 64/150\n",
      "Epoch 64/150, Loss: 0.1447, Accuracy: 0.95\n",
      "Start epoch 65/150\n",
      "Epoch 65/150, Loss: 0.1428, Accuracy: 0.95\n",
      "Start epoch 66/150\n",
      "Epoch 66/150, Loss: 0.1515, Accuracy: 0.95\n",
      "Start epoch 67/150\n",
      "Epoch 67/150, Loss: 0.1645, Accuracy: 0.95\n",
      "Start epoch 68/150\n",
      "Epoch 68/150, Loss: 0.1450, Accuracy: 0.95\n",
      "Start epoch 69/150\n",
      "Epoch 69/150, Loss: 0.1401, Accuracy: 0.95\n",
      "Start epoch 70/150\n",
      "Epoch 70/150, Loss: 0.1283, Accuracy: 0.96\n",
      "Start epoch 71/150\n",
      "Epoch 71/150, Loss: 0.1293, Accuracy: 0.95\n",
      "Start epoch 72/150\n",
      "Epoch 72/150, Loss: 0.1336, Accuracy: 0.95\n",
      "Start epoch 73/150\n",
      "Epoch 73/150, Loss: 0.1387, Accuracy: 0.95\n",
      "Start epoch 74/150\n",
      "Epoch 74/150, Loss: 0.1285, Accuracy: 0.96\n",
      "Start epoch 75/150\n",
      "Epoch 75/150, Loss: 0.1343, Accuracy: 0.96\n",
      "Start epoch 76/150\n",
      "Epoch 76/150, Loss: 0.1338, Accuracy: 0.95\n",
      "Start epoch 77/150\n",
      "Epoch 77/150, Loss: 0.1249, Accuracy: 0.96\n",
      "Start epoch 78/150\n",
      "Epoch 78/150, Loss: 0.1178, Accuracy: 0.96\n",
      "Start epoch 79/150\n",
      "Epoch 79/150, Loss: 0.1238, Accuracy: 0.96\n",
      "Start epoch 80/150\n",
      "Epoch 80/150, Loss: 0.1108, Accuracy: 0.96\n",
      "Start epoch 81/150\n",
      "Epoch 81/150, Loss: 0.1182, Accuracy: 0.96\n",
      "Start epoch 82/150\n",
      "Epoch 82/150, Loss: 0.1221, Accuracy: 0.96\n",
      "Start epoch 83/150\n",
      "Epoch 83/150, Loss: 0.1102, Accuracy: 0.96\n",
      "Start epoch 84/150\n",
      "Epoch 84/150, Loss: 0.1063, Accuracy: 0.96\n",
      "Start epoch 85/150\n",
      "Epoch 85/150, Loss: 0.1111, Accuracy: 0.96\n",
      "Start epoch 86/150\n",
      "Epoch 86/150, Loss: 0.1085, Accuracy: 0.96\n",
      "Start epoch 87/150\n",
      "Epoch 87/150, Loss: 0.1032, Accuracy: 0.96\n",
      "Start epoch 88/150\n",
      "Epoch 88/150, Loss: 0.1123, Accuracy: 0.96\n",
      "Start epoch 89/150\n",
      "Epoch 89/150, Loss: 0.0983, Accuracy: 0.97\n",
      "Start epoch 90/150\n",
      "Epoch 90/150, Loss: 0.1050, Accuracy: 0.96\n",
      "Start epoch 91/150\n",
      "Epoch 91/150, Loss: 0.1094, Accuracy: 0.96\n",
      "Start epoch 92/150\n",
      "Epoch 92/150, Loss: 0.1355, Accuracy: 0.96\n",
      "Start epoch 93/150\n",
      "Epoch 93/150, Loss: 0.1142, Accuracy: 0.96\n",
      "Start epoch 94/150\n",
      "Epoch 94/150, Loss: 0.0978, Accuracy: 0.97\n",
      "Start epoch 95/150\n",
      "Epoch 95/150, Loss: 0.1202, Accuracy: 0.96\n",
      "Start epoch 96/150\n",
      "Epoch 96/150, Loss: 0.1093, Accuracy: 0.96\n",
      "Start epoch 97/150\n",
      "Epoch 97/150, Loss: 0.1219, Accuracy: 0.97\n",
      "Start epoch 98/150\n",
      "Epoch 98/150, Loss: 0.1059, Accuracy: 0.97\n",
      "Start epoch 99/150\n",
      "Epoch 99/150, Loss: 0.0944, Accuracy: 0.97\n",
      "Start epoch 100/150\n",
      "Epoch 100/150, Loss: 0.0922, Accuracy: 0.97\n",
      "Start epoch 101/150\n",
      "Epoch 101/150, Loss: 0.0939, Accuracy: 0.97\n",
      "Start epoch 102/150\n",
      "Epoch 102/150, Loss: 0.0916, Accuracy: 0.97\n",
      "Start epoch 103/150\n",
      "Epoch 103/150, Loss: 0.1067, Accuracy: 0.96\n",
      "Start epoch 104/150\n",
      "Epoch 104/150, Loss: 0.1054, Accuracy: 0.96\n",
      "Start epoch 105/150\n",
      "Epoch 105/150, Loss: 0.0905, Accuracy: 0.97\n",
      "Start epoch 106/150\n",
      "Epoch 106/150, Loss: 0.0893, Accuracy: 0.97\n",
      "Start epoch 107/150\n",
      "Epoch 107/150, Loss: 0.0884, Accuracy: 0.97\n",
      "Start epoch 108/150\n",
      "Epoch 108/150, Loss: 0.0925, Accuracy: 0.97\n",
      "Start epoch 109/150\n",
      "Epoch 109/150, Loss: 0.1275, Accuracy: 0.97\n",
      "Start epoch 110/150\n",
      "Epoch 110/150, Loss: 0.0921, Accuracy: 0.97\n",
      "Start epoch 111/150\n",
      "Epoch 111/150, Loss: 0.0803, Accuracy: 0.97\n",
      "Start epoch 112/150\n",
      "Epoch 112/150, Loss: 0.0793, Accuracy: 0.97\n",
      "Start epoch 113/150\n",
      "Epoch 113/150, Loss: 0.0871, Accuracy: 0.97\n",
      "Start epoch 114/150\n",
      "Epoch 114/150, Loss: 0.0918, Accuracy: 0.97\n",
      "Start epoch 115/150\n",
      "Epoch 115/150, Loss: 0.0936, Accuracy: 0.97\n",
      "Start epoch 116/150\n",
      "Epoch 116/150, Loss: 0.0886, Accuracy: 0.97\n",
      "Start epoch 117/150\n",
      "Epoch 117/150, Loss: 0.0765, Accuracy: 0.97\n",
      "Start epoch 118/150\n",
      "Epoch 118/150, Loss: 0.0877, Accuracy: 0.97\n",
      "Start epoch 119/150\n",
      "Epoch 119/150, Loss: 0.0889, Accuracy: 0.97\n",
      "Start epoch 120/150\n",
      "Epoch 120/150, Loss: 0.0767, Accuracy: 0.97\n",
      "Start epoch 121/150\n",
      "Epoch 121/150, Loss: 0.0813, Accuracy: 0.97\n",
      "Start epoch 122/150\n",
      "Epoch 122/150, Loss: 0.0825, Accuracy: 0.97\n",
      "Start epoch 123/150\n",
      "Epoch 123/150, Loss: 0.0868, Accuracy: 0.97\n",
      "Start epoch 124/150\n",
      "Epoch 124/150, Loss: 0.0695, Accuracy: 0.98\n",
      "Start epoch 125/150\n",
      "Epoch 125/150, Loss: 0.0652, Accuracy: 0.98\n",
      "Start epoch 126/150\n",
      "Epoch 126/150, Loss: 0.0715, Accuracy: 0.98\n",
      "Start epoch 127/150\n",
      "Epoch 127/150, Loss: 0.0698, Accuracy: 0.98\n",
      "Start epoch 128/150\n",
      "Epoch 128/150, Loss: 0.0780, Accuracy: 0.98\n",
      "Start epoch 129/150\n",
      "Epoch 129/150, Loss: 0.0764, Accuracy: 0.97\n",
      "Start epoch 130/150\n",
      "Epoch 130/150, Loss: 0.0689, Accuracy: 0.98\n",
      "Start epoch 131/150\n",
      "Epoch 131/150, Loss: 0.0709, Accuracy: 0.98\n",
      "Start epoch 132/150\n",
      "Epoch 132/150, Loss: 0.0744, Accuracy: 0.98\n",
      "Start epoch 133/150\n",
      "Epoch 133/150, Loss: 0.0817, Accuracy: 0.97\n",
      "Start epoch 134/150\n",
      "Epoch 134/150, Loss: 0.0663, Accuracy: 0.98\n",
      "Start epoch 135/150\n",
      "Epoch 135/150, Loss: 0.0704, Accuracy: 0.98\n",
      "Start epoch 136/150\n",
      "Epoch 136/150, Loss: 0.0688, Accuracy: 0.98\n",
      "Start epoch 137/150\n",
      "Epoch 137/150, Loss: 0.0539, Accuracy: 0.98\n",
      "Start epoch 138/150\n",
      "Epoch 138/150, Loss: 0.0623, Accuracy: 0.98\n",
      "Start epoch 139/150\n",
      "Epoch 139/150, Loss: 0.0649, Accuracy: 0.98\n",
      "Start epoch 140/150\n",
      "Epoch 140/150, Loss: 0.0651, Accuracy: 0.98\n",
      "Start epoch 141/150\n",
      "Epoch 141/150, Loss: 0.0611, Accuracy: 0.98\n",
      "Start epoch 142/150\n",
      "Epoch 142/150, Loss: 0.0664, Accuracy: 0.98\n",
      "Start epoch 143/150\n",
      "Epoch 143/150, Loss: 0.0580, Accuracy: 0.98\n",
      "Start epoch 144/150\n",
      "Epoch 144/150, Loss: 0.0856, Accuracy: 0.97\n",
      "Start epoch 145/150\n",
      "Epoch 145/150, Loss: 0.0817, Accuracy: 0.98\n",
      "Start epoch 146/150\n",
      "Epoch 146/150, Loss: 0.0612, Accuracy: 0.98\n",
      "Start epoch 147/150\n",
      "Epoch 147/150, Loss: 0.0589, Accuracy: 0.98\n",
      "Start epoch 148/150\n",
      "Epoch 148/150, Loss: 0.0592, Accuracy: 0.98\n",
      "Start epoch 149/150\n",
      "Epoch 149/150, Loss: 0.0567, Accuracy: 0.98\n",
      "Start epoch 150/150\n",
      "Epoch 150/150, Loss: 0.0666, Accuracy: 0.98\n",
      "Training completed in 13618.41 seconds\n",
      "Training accuracy: 0.98\n",
      "--------------------------------\n",
      "Training completed, stats:\n",
      "Training accuracy: 0.9772979727853374\n",
      "Training loss: [1.4613601813274146, 1.0702507849288199, 0.9039985062801732, 0.7960728294158403, 0.7185318170659309, 0.6594736489046992, 0.6123157423154443, 0.5718198439716238, 0.5280138135483835, 0.49360124786606935, 0.4694243676103322, 0.45354092958490405, 0.4197241525470683, 0.3996960939097721, 0.3855059084243479, 0.38717856930684197, 0.36110198725245696, 0.349708960910814, 0.341909363602115, 0.31386433943974235, 0.3170509555632562, 0.30007687052794263, 0.30237563142338686, 0.29388203435635146, 0.2824439292987891, 0.28508870999238134, 0.2834808908205117, 0.26714519111324203, 0.25513640899969414, 0.2479525048912099, 0.25651730834382824, 0.24678817701286973, 0.24809767017388237, 0.23335497504907898, 0.2412341105529165, 0.2369127575209183, 0.2269422393951532, 0.21820546889397424, 0.2091944922519996, 0.20280359093660275, 0.21786317443557546, 0.22159205670509718, 0.20681708089314996, 0.18964689877708402, 0.18564450450703107, 0.204865540484939, 0.19894614535491023, 0.16954546967372958, 0.17900864104122188, 0.17544155421180535, 0.19566313005917896, 0.19066642877538648, 0.1649302584242768, 0.17224910743204894, 0.18657646127111088, 0.17280869687025527, 0.17258078161528154, 0.18458231055565114, 0.16908095554506355, 0.17182572189289913, 0.15063405107805686, 0.1494564755976332, 0.1391460226634435, 0.14469381254908126, 0.14278304717808435, 0.15148831262723006, 0.16452909389560202, 0.1449707423015374, 0.14008064195513725, 0.12830848983629087, 0.12933696914398302, 0.13362699521260452, 0.1386872203361276, 0.12847651322001377, 0.13426378410540324, 0.1338160556567981, 0.12493266399735503, 0.11776292274615406, 0.12381188220352726, 0.11078007366771983, 0.1182220169751023, 0.12208853431655901, 0.11018554388702048, 0.1063471325236348, 0.11110952453259214, 0.10853988660779675, 0.10318612919984368, 0.11233533389837506, 0.09831078172109164, 0.1050485857098932, 0.10941955140602272, 0.1355404199133998, 0.11423526220518139, 0.09784840555053896, 0.12019862895584212, 0.10934005137038443, 0.12193030687213867, 0.10585566816142702, 0.09435088350231537, 0.09220597958109811, 0.0939030396933379, 0.0915771895541554, 0.10671035362720753, 0.10542166246661702, 0.09054327012756758, 0.08927517954416705, 0.08841190607476551, 0.09247113861951285, 0.12752472950491758, 0.092145471179454, 0.08033187384923211, 0.07926476133608185, 0.08706875000997916, 0.09177209091974439, 0.0935983909582472, 0.08862835602562842, 0.07648093302824856, 0.08772182753680488, 0.08889579634075012, 0.07674523324301813, 0.08128275932430958, 0.08254352281698381, 0.08684379976465309, 0.06946380397993082, 0.06522969256847504, 0.07148693552224246, 0.06977773529469175, 0.07801015059199942, 0.07644796587291908, 0.06887955909421815, 0.07089488006782084, 0.07436531689018011, 0.08168177394427162, 0.06631185613424245, 0.07043784177878591, 0.06883543566285542, 0.05388153458541605, 0.06233153671986399, 0.06492731557227671, 0.06512748213089277, 0.06106755971512963, 0.06639070597897588, 0.05804014430418446, 0.0856116700791795, 0.08166894539922838, 0.06115126814507772, 0.05887841924085422, 0.05924107541332219, 0.05666289093854746, 0.06657265982203252]\n",
      "Time elapsed: 13618.407377004623\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the model\n",
    "training_accuracy, training_loss, time_elapsed_tr = train(device=device, model=model, train_loader=train_loader, criterion=criterion, optimizer=optimizer, num_epochs=num_epochs)\n",
    "\n",
    "print (\"Training completed, stats:\")\n",
    "print(f\"Training accuracy: {training_accuracy}\")\n",
    "print(f\"Training loss: {training_loss}\")\n",
    "print(f\"Time elapsed: {time_elapsed_tr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/6n_j7xxd6xlb0k2ypkc2pn240000gn/T/ipykernel_36791/121095286.py:293: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  target_size = (max(x_H.shape[2], x_W.shape[2]), max(x_H.shape[3], x_W.shape[3]))\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"lsgnet-{num_epochs}-epochs\"\n",
    "\n",
    "#save model with jit\n",
    "input_test = torch.randn(1, 3, 224, 224)\n",
    "input_test = input_test.to(device)\n",
    "\n",
    "traced_model = torch.jit.trace(model, input_test)\n",
    "\n",
    "traced_model.save(f\"{file_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.38%\n",
      "Precision: 0.95\n",
      "Recall: 0.94\n",
      "Validation Accuracy: 96.38084632516704%\n",
      "Validation Precision: 0.9491139519066106\n",
      "Validation Recall: 0.9448535313523843\n",
      "Confusion Matrix:\n",
      "[[224   0   1   2   6   1   1   0]\n",
      " [  2 120   4   2   3   0   0   0]\n",
      " [  1   3 204   1   0   1   0   0]\n",
      " [  0   0   0 118   1   0   1   0]\n",
      " [  3   4   1   6 191   2   2   1]\n",
      " [  1   0   0   4   0 619   0   0]\n",
      " [  1   1   3   2   0   2  55   2]\n",
      " [  0   0   0   0   0   0   0 200]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    validation_accuracy, validation_precision, validation_recall, confusion_matrix = validate(device, model, validation_loader)\n",
    "    print(f\"Validation Accuracy: {validation_accuracy}%\")\n",
    "    print(f\"Validation Precision: {validation_precision}\")\n",
    "    print(f\"Validation Recall: {validation_recall}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Runtime error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
